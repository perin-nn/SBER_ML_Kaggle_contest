{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQ5FY4B17U54"
   },
   "source": [
    "# Продвинутое решение с использованием техник машинного обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T22:40:41.369222Z",
     "iopub.status.busy": "2025-12-14T22:40:41.369138Z",
     "iopub.status.idle": "2025-12-14T22:40:42.420832Z",
     "shell.execute_reply": "2025-12-14T22:40:42.420401Z"
    },
    "id": "F49UAvbMTYda"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRd7JAXQ97--"
   },
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysR5lXoq99t9"
   },
   "source": [
    "Загрузим датасет из соревнования. Обучение и валидацию будем проводить на train части. Часть test содержит в себе признаки без таргета, по ней будем строить предсказания для дальнейшей отправки в submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T22:40:42.422140Z",
     "iopub.status.busy": "2025-12-14T22:40:42.421909Z",
     "iopub.status.idle": "2025-12-14T22:40:43.027640Z",
     "shell.execute_reply": "2025-12-14T22:40:43.027281Z"
    },
    "id": "lI3jRT3LM_o6",
    "outputId": "25321858-0a0b-4ba4-b92c-dfc8684846fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1117957, 22), Test: (745305, 21)\n",
      "Target range: [0.2850, 0.7250]\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "X_full = train.drop(columns=['id', 'FloodProbability'])\n",
    "y_full = train['FloodProbability']\n",
    "X_test = test.drop(columns=['id'])\n",
    "test_ids = test['id']\n",
    "\n",
    "original_features = X_full.columns.tolist()\n",
    "\n",
    "print(f'Train: {train.shape}, Test: {test.shape}')\n",
    "print(f'Target range: [{y_full.min():.4f}, {y_full.max():.4f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "cp-Kdkh9Eugx",
    "outputId": "00c64e0a-098f-4d4d-c37b-c9ade6fdd0ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MonsoonIntensity</th>\n",
       "      <th>TopographyDrainage</th>\n",
       "      <th>RiverManagement</th>\n",
       "      <th>Deforestation</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>ClimateChange</th>\n",
       "      <th>DamsQuality</th>\n",
       "      <th>Siltation</th>\n",
       "      <th>AgriculturalPractices</th>\n",
       "      <th>...</th>\n",
       "      <th>DrainageSystems</th>\n",
       "      <th>CoastalVulnerability</th>\n",
       "      <th>Landslides</th>\n",
       "      <th>Watersheds</th>\n",
       "      <th>DeterioratingInfrastructure</th>\n",
       "      <th>PopulationScore</th>\n",
       "      <th>WetlandLoss</th>\n",
       "      <th>InadequatePlanning</th>\n",
       "      <th>PoliticalFactors</th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  MonsoonIntensity  TopographyDrainage  RiverManagement  Deforestation  \\\n",
       "0   0                 5                   8                5              8   \n",
       "1   1                 6                   7                4              4   \n",
       "2   2                 6                   5                6              7   \n",
       "3   3                 3                   4                6              5   \n",
       "4   4                 5                   3                2              6   \n",
       "\n",
       "   Urbanization  ClimateChange  DamsQuality  Siltation  AgriculturalPractices  \\\n",
       "0             6              4            4          3                      3   \n",
       "1             8              8            3          5                      4   \n",
       "2             3              7            1          5                      4   \n",
       "3             4              8            4          7                      6   \n",
       "4             4              4            3          3                      3   \n",
       "\n",
       "   ...  DrainageSystems  CoastalVulnerability  Landslides  Watersheds  \\\n",
       "0  ...                5                     3           3           5   \n",
       "1  ...                7                     2           0           3   \n",
       "2  ...                7                     3           7           5   \n",
       "3  ...                2                     4           7           4   \n",
       "4  ...                2                     2           6           6   \n",
       "\n",
       "   DeterioratingInfrastructure  PopulationScore  WetlandLoss  \\\n",
       "0                            4                7            5   \n",
       "1                            5                3            3   \n",
       "2                            6                8            2   \n",
       "3                            4                6            5   \n",
       "4                            4                1            2   \n",
       "\n",
       "   InadequatePlanning  PoliticalFactors  FloodProbability  \n",
       "0                   7                 3             0.445  \n",
       "1                   4                 3             0.450  \n",
       "2                   3                 3             0.530  \n",
       "3                   7                 5             0.535  \n",
       "4                   3                 5             0.415  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JjyaICQB_-L"
   },
   "source": [
    "Загрузим решение из прошлого ноутбука с бейзлайном для сравнения с продвинутым решением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-14T22:40:43.028714Z",
     "iopub.status.busy": "2025-12-14T22:40:43.028624Z",
     "iopub.status.idle": "2025-12-14T22:40:43.042304Z",
     "shell.execute_reply": "2025-12-14T22:40:43.041929Z"
    },
    "id": "yfj6X802TYdd",
    "outputId": "757adab3-1125-440e-fee4-3a694510d04e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline: R² = 0.858277\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    baseline_train_oof = np.load('baseline_output/baseline_predictions_train_oof.npy')\n",
    "    baseline_test = np.load('baseline_output/baseline_predictions_test.npy')\n",
    "    baseline_r2 = r2_score(y_full, baseline_train_oof)\n",
    "    print(f'baseline: R² = {baseline_r2:.6f}')\n",
    "    BASELINE_AVAILABLE = True\n",
    "except FileNotFoundError:\n",
    "    print('Файл не найден')\n",
    "    BASELINE_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ezr1Y5b4CQyU"
   },
   "source": [
    "Теперь проводим обработку признаков. Для начала - винсоризация и масштабирования с помощью робастного scaler, как для бейзлайна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "x4wsVQ7pN-gC"
   },
   "outputs": [],
   "source": [
    "def preprocess(df, scaler=None, fit=False):\n",
    "    df_win = df.copy()\n",
    "    for col in df.columns:\n",
    "        df_win[col] = winsorize(df[col], limits=(0.01, 0.01))\n",
    "\n",
    "    if fit:\n",
    "        scaler = RobustScaler()\n",
    "        df_scaled = pd.DataFrame(scaler.fit_transform(df_win), columns=df.columns, index=df.index)\n",
    "        return df_scaled, scaler\n",
    "    else:\n",
    "        df_scaled = pd.DataFrame(scaler.transform(df_win), columns=df.columns, index=df.index)\n",
    "        return df_scaled\n",
    "\n",
    "X_full_scaled, scaler = preprocess(X_full, fit=True)\n",
    "X_test_scaled = preprocess(X_test, scaler=scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMJl7bz2CrGq"
   },
   "source": [
    "Получили предобработку для обучающей и тестовой части, тестовую мы снова будем использовать только в конце для получения submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ww6T9kLiD2E6"
   },
   "source": [
    "## Генерация признаков x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIC038o8D9cw"
   },
   "source": [
    "Сейчас будем генерировать новые признаки помимо тех, что делали для бейзлайна. Изучив решение победителя, мы обнаружили, что сумма значений признаков очень скоррелирована с таргетом. Мы развиваем эту идею. Во-первых, мы добавляем порядковые признаки, например сумму значений признаков выше трешхолда или ниже его. Это может помочь выделить сумму по экстремальным значениям, которые предположительно больше влияют на таргет. Также добавляем сортировку значений признаков и считаем k-ые статистики. Во-вторых, добавляем \"магическую\" фичу - стандартное отклонение целевой переменной для групп с одинаковой суммой по всем фичам. Для теста заполним средним значением из обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-14T22:40:44.494235Z",
     "iopub.status.busy": "2025-12-14T22:40:44.494144Z",
     "iopub.status.idle": "2025-12-14T22:40:47.805147Z",
     "shell.execute_reply": "2025-12-14T22:40:47.804853Z"
    },
    "id": "aFQWPCWrTYde",
    "outputId": "7fe6e9d6-da4c-4cf7-d1a2-b9d3d4fabb36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего фичей: 58 (20 исходных + 38 новых)\n"
     ]
    }
   ],
   "source": [
    "def generate_features(df_orig, df_scaled, y=None, is_train=True):\n",
    "    features = df_scaled.copy()\n",
    "\n",
    "    # новые фичи из бейзлайна\n",
    "    features['sum'] = df_orig.sum(axis=1)\n",
    "    features['mean'] = df_orig.mean(axis=1)\n",
    "    features['std'] = df_orig.std(axis=1)\n",
    "    features['max'] = df_orig.max(axis=1)\n",
    "    features['min'] = df_orig.min(axis=1)\n",
    "    features['median'] = df_orig.median(axis=1)\n",
    "    features['range'] = features['max'] - features['min']\n",
    "    features['q25'] = df_orig.quantile(0.25, axis=1)\n",
    "    features['q75'] = df_orig.quantile(0.75, axis=1)\n",
    "    features['iqr'] = features['q75'] - features['q25']\n",
    "    features['cv'] = features['std'] / (features['mean'] + 1e-10)\n",
    "\n",
    "    # новые порядковые фичи\n",
    "    # количество значений в строке, проходящих порог\n",
    "    for threshold in [6, 7, 8]:\n",
    "        features[f'nb_sup{threshold}'] = (df_orig > threshold).sum(axis=1)\n",
    "    for threshold in [2, 3, 4]:\n",
    "        features[f'nb_inf{threshold}'] = (df_orig < threshold).sum(axis=1)\n",
    "\n",
    "    # i-тое значение в отсортированной по возрастанию строке\n",
    "    sorted_vals = np.sort(df_orig.values, axis=1)\n",
    "    for i in range(sorted_vals.shape[1]):\n",
    "        features[f'sorted_{i}'] = sorted_vals[:, i]\n",
    "\n",
    "    if is_train and y is not None:\n",
    "        temp_df = features[['sum']].copy()\n",
    "        temp_df['target'] = y\n",
    "        features['magic_std'] = temp_df.groupby('sum')['target'].transform('std')\n",
    "        features['magic_std'].fillna(features['magic_std'].mean(), inplace=True)\n",
    "    else:\n",
    "        features['magic_std'] = 0\n",
    "\n",
    "    return features\n",
    "\n",
    "X_full_feat = generate_features(X_full, X_full_scaled, y_full, is_train=True)\n",
    "X_test_feat = generate_features(X_test, X_test_scaled, is_train=False)\n",
    "\n",
    "X_test_feat['magic_std'] = X_full_feat['magic_std'].mean()\n",
    "\n",
    "print(f'Всего фичей: {X_full_feat.shape[1]} ({len(original_features)} исходных + {X_full_feat.shape[1] - len(original_features)} новых)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmUU5_51OrBN"
   },
   "source": [
    "## Модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NA3AzhTEOnga"
   },
   "source": [
    "Функция для обучения с RepeatedStratifiedKFold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "H6kWU45nbBdP"
   },
   "outputs": [],
   "source": [
    "n_repeats = 3\n",
    "n_splits = 5\n",
    "seed = 42\n",
    "y_discrete = (y_full * 400).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "mKGyq0oTOmQt"
   },
   "outputs": [],
   "source": [
    "def train_model_cv_separate_repeats(model, X, y, model_name, use_aug=False):\n",
    "    oofs_per_repeat = []\n",
    "    preds_per_repeat = []\n",
    "\n",
    "    total_folds = n_repeats * n_splits\n",
    "    pbar = tqdm(total=total_folds, desc=f'{model_name:12}',\n",
    "                bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}] {postfix}')\n",
    "\n",
    "    fold_idx = 0\n",
    "    for repeat in range(n_repeats):\n",
    "        oof_repeat = np.zeros(len(X))\n",
    "        pred_repeat = np.zeros(len(X_test_feat))\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed + repeat)\n",
    "\n",
    "        for train_idx, val_idx in skf.split(X, y_discrete):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            # Аугментация если нужно\n",
    "            if use_aug:\n",
    "                np.random.seed(fold_idx)\n",
    "                X_train = X_train + np.random.normal(0, 0.01, X_train.shape)\n",
    "                y_train = y_train * 0.95 + y_train.mean() * 0.05\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            oof_repeat[val_idx] = model.predict(X_val)\n",
    "            pred_repeat += model.predict(X_test_feat) / n_splits\n",
    "            fold_r2 = r2_score(y_val, oof_repeat[val_idx])\n",
    "\n",
    "            pbar.set_postfix({'R²': f'{fold_r2:.6f}', 'Repeat': repeat+1})\n",
    "            pbar.update(1)\n",
    "            fold_idx += 1\n",
    "\n",
    "        oofs_per_repeat.append(oof_repeat)\n",
    "        preds_per_repeat.append(pred_repeat)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    oof_combined = np.mean(oofs_per_repeat, axis=0)\n",
    "    oof_r2 = r2_score(y, oof_combined)\n",
    "\n",
    "    return oofs_per_repeat, preds_per_repeat, oof_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_pseudolabeling(model_class, params, X_train, y_train, X_test, model_name, use_aug=False):\n",
    "    # Базовая модель\n",
    "    model_base = model_class(**params)\n",
    "    base_oofs, base_preds, _ = train_model_cv_separate_repeats(\n",
    "        model_base, X_train, y_train, f\"{model_name}_base\", use_aug=use_aug\n",
    "    )\n",
    "    \n",
    "    # Получаем pseudo-labels\n",
    "    pseudo_labels = np.mean(base_preds, axis=0)\n",
    "    conf_low = np.percentile(pseudo_labels, 25)\n",
    "    conf_high = np.percentile(pseudo_labels, 75)\n",
    "    confident_mask = (pseudo_labels >= conf_low) & (pseudo_labels <= conf_high)\n",
    "    \n",
    "    X_pseudo = X_test.iloc[confident_mask]\n",
    "    y_pseudo = pseudo_labels[confident_mask]\n",
    "    X_augmented = pd.concat([X_train, X_pseudo], ignore_index=True)\n",
    "    y_augmented = pd.concat([y_train, pd.Series(y_pseudo)], ignore_index=True)\n",
    "    \n",
    "    # Дообучение на расширенных данных\n",
    "    final_oofs = []\n",
    "    final_preds = []\n",
    "    \n",
    "    for repeat in range(n_repeats):\n",
    "        oof_repeat = np.zeros(len(y_train))\n",
    "        pred_repeat = np.zeros(len(X_test))\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed + repeat)\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_discrete)):\n",
    "            train_idx_aug = np.concatenate([train_idx, np.arange(len(y_train), len(y_augmented))])\n",
    "            model = model_class(**params)\n",
    "            model.fit(X_augmented.iloc[train_idx_aug], y_augmented.iloc[train_idx_aug])\n",
    "            oof_repeat[val_idx] = model.predict(X_train.iloc[val_idx])\n",
    "            pred_repeat += model.predict(X_test) / n_splits\n",
    "        \n",
    "        final_oofs.append(oof_repeat)\n",
    "        final_preds.append(pred_repeat)\n",
    "    \n",
    "    final_score = r2_score(y_train, np.mean(final_oofs, axis=0))\n",
    "    return final_oofs, final_preds, final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B Тесты дополнительных техник\n",
    "\n",
    "Проверяем эффективность дополнительных методов улучшения качества.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature Jittering & Label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "БЕЗ аугментации 0.8690295999210678\n",
      "Feature Jittering 0.8682842422163891\n",
      "Label Smoothing 0.8668842747551073\n",
      "Jittering + Smoothing 0.8660455759446903\n"
     ]
    }
   ],
   "source": [
    "test_params = {\n",
    "    'device': 'cuda',\n",
    "    'tree_method': 'hist',\n",
    "    'random_state': 42,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 1000,\n",
    "    'max_depth': 6,\n",
    "}\n",
    "\n",
    "def train_with_augmentation(X, y, X_test, params, aug_type='none'):\n",
    "    \"\"\"\n",
    "    aug_type: 'none', 'jittering', 'smoothing', 'both'\n",
    "    \"\"\"\n",
    "    oofs = []\n",
    "    for repeat in range(n_repeats):\n",
    "        oof_repeat = np.zeros(len(X))\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed + repeat)\n",
    "        \n",
    "        fold_idx = 0\n",
    "        for train_idx, val_idx in skf.split(X, y_discrete):\n",
    "            X_train, X_val = X.iloc[train_idx].copy(), X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx].copy(), y.iloc[val_idx]\n",
    "            \n",
    "            if aug_type in ['jittering', 'both']:\n",
    "                np.random.seed(fold_idx)\n",
    "                X_train = X_train + np.random.normal(0, 0.01, X_train.shape)\n",
    "            \n",
    "            if aug_type in ['smoothing', 'both']:\n",
    "                y_train = y_train * 0.95 + y_train.mean() * 0.05\n",
    "            \n",
    "            model = XGBRegressor(**params)\n",
    "            model.fit(X_train, y_train)\n",
    "            oof_repeat[val_idx] = model.predict(X_val)\n",
    "            fold_idx += 1\n",
    "        \n",
    "        oofs.append(oof_repeat)\n",
    "    \n",
    "    oof_combined = np.mean(oofs, axis=0)\n",
    "    return r2_score(y, oof_combined)\n",
    "\n",
    "\n",
    "score_baseline = train_with_augmentation(X_full_feat, y_full, X_test_feat, test_params, 'none')\n",
    "print('БЕЗ аугментации', score_baseline)\n",
    "\n",
    "score_jitter = train_with_augmentation(X_full_feat, y_full, X_test_feat, test_params, 'jittering')\n",
    "print('Feature Jittering', score_jitter)\n",
    "\n",
    "score_smooth = train_with_augmentation(X_full_feat, y_full, X_test_feat, test_params, 'smoothing')\n",
    "print('Label Smoothing', score_smooth)\n",
    "\n",
    "score_both = train_with_augmentation(X_full_feat, y_full, X_test_feat, test_params, 'both')\n",
    "print('Jittering + Smoothing', score_both)\n",
    "\n",
    "score_no_aug = score_baseline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pseudo-labeling\n",
    "\n",
    "Проверяем, помогает ли использование предсказаний на тестовых данных для дообучения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Без Pseudo-labeling 0.8690295999210678\n",
      "С Pseudo-labeling 0.8692091004018079\n"
     ]
    }
   ],
   "source": [
    "score_no_pseudo = score_no_aug\n",
    "\n",
    "base_model = XGBRegressor(**test_params)\n",
    "base_model.fit(X_full_feat, y_full)\n",
    "\n",
    "pseudo_labels = base_model.predict(X_test_feat)\n",
    "\n",
    "confidence_threshold_low = np.percentile(pseudo_labels, 25)\n",
    "confidence_threshold_high = np.percentile(pseudo_labels, 75)\n",
    "confident_mask = (pseudo_labels >= confidence_threshold_low) & (pseudo_labels <= confidence_threshold_high)\n",
    "\n",
    "X_pseudo = X_test_feat.iloc[confident_mask]\n",
    "y_pseudo = pseudo_labels[confident_mask]\n",
    "\n",
    "# Объединяем с обучающими данными\n",
    "X_augmented = np.vstack([X_full_feat, X_pseudo])\n",
    "y_augmented = np.concatenate([y_full, y_pseudo])\n",
    "\n",
    "# Обучаем на расширенных данных\n",
    "# используем только первые len(y_full) для OOF оценки\n",
    "oofs_pseudo = []\n",
    "for repeat in range(n_repeats):\n",
    "    oof_repeat = np.zeros(len(y_full))\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed + repeat)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_full_feat, y_discrete)):\n",
    "        train_idx_aug = np.concatenate([train_idx, np.arange(len(y_full), len(y_augmented))])\n",
    "        \n",
    "        model = XGBRegressor(**test_params)\n",
    "        model.fit(X_augmented[train_idx_aug], y_augmented[train_idx_aug])\n",
    "        \n",
    "        oof_repeat[val_idx] = model.predict(X_full_feat.iloc[val_idx])\n",
    "    \n",
    "    oofs_pseudo.append(oof_repeat)\n",
    "\n",
    "oof_pseudo_combined = np.mean(oofs_pseudo, axis=0)\n",
    "score_with_pseudo = r2_score(y_full, oof_pseudo_combined)\n",
    "\n",
    "delta = score_with_pseudo - score_no_pseudo\n",
    "print('Без Pseudo-labeling', score_no_pseudo)\n",
    "print('С Pseudo-labeling', score_with_pseudo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Stacking (Multi-level Ensemble)\n",
    "\n",
    "Проверяем, помогает ли добавление второго уровня мета-моделей (стекинг vs простой блендинг).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54b4624256c4e5b828d3ad6e56a5340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_model_0:   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d95047c49f9445a95c40df2e18cc978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_model_1:   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888f0bb966174e1da27cd9cebf943899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_model_2:   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf7160a478546c29ef27794bbab8829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_model_3:   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e786749789674faa936a91e746652104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_model_4:   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLENDING 0.8692850213224765\n",
      "STACKING 0.8685832345467893\n"
     ]
    }
   ],
   "source": [
    "test_models_configs = [\n",
    "    {'max_depth': 5, 'learning_rate': 0.1, 'n_estimators': 500},\n",
    "    {'max_depth': 6, 'learning_rate': 0.1, 'n_estimators': 500},\n",
    "    {'max_depth': 7, 'learning_rate': 0.1, 'n_estimators': 500},\n",
    "    {'max_depth': 5, 'learning_rate': 0.05, 'n_estimators': 1000},\n",
    "    {'max_depth': 6, 'learning_rate': 0.05, 'n_estimators': 1000},\n",
    "]\n",
    "\n",
    "test_oofs = []\n",
    "for idx, config in enumerate(test_models_configs):\n",
    "    params = {**test_params, **config}\n",
    "    oofs_repeat, _, _ = train_model_cv_separate_repeats(\n",
    "        XGBRegressor(**params), \n",
    "        X_full_feat, \n",
    "        y_full, \n",
    "        f'test_model_{idx}',\n",
    "        use_aug=False\n",
    "    )\n",
    "    oof_avg = np.mean(oofs_repeat, axis=0)\n",
    "    test_oofs.append(oof_avg)\n",
    "\n",
    "blend_X_test = np.column_stack(test_oofs)\n",
    "ridge_blend = Ridge(alpha=0.001, fit_intercept=False, random_state=42)\n",
    "ridge_blend.fit(blend_X_test, y_full)\n",
    "blend_pred = ridge_blend.predict(blend_X_test)\n",
    "score_blending = r2_score(y_full, blend_pred)\n",
    "print('BLENDING', score_blending)\n",
    "\n",
    "meta_oof = np.zeros(len(y_full))\n",
    "meta_model_params = {\n",
    "    'device': 'cuda',\n",
    "    'tree_method': 'hist',\n",
    "    'random_state': 42,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 3,\n",
    "}\n",
    "\n",
    "for repeat in range(n_repeats):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed + repeat)\n",
    "    oof_X = blend_X_test\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(oof_X, y_discrete)):\n",
    "        meta_model = XGBRegressor(**meta_model_params)\n",
    "        meta_model.fit(oof_X[train_idx], y_full.iloc[train_idx])\n",
    "        meta_oof[val_idx] += meta_model.predict(oof_X[val_idx]) / n_repeats\n",
    "\n",
    "score_stacking = r2_score(y_full, meta_oof)\n",
    "print('STACKING', score_stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Voting (Simple Averaging)\n",
    "\n",
    "Проверяем, помогает ли простое усреднение (mean/median) vs взвешенный Ridge блендинг.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "равные веса 0.8692849692550277\n",
      "робастное усреднение 0.86927598581468\n",
      "отбрасываем крайние 20% 0.8692849692550277\n",
      "оптимальные веса 0.8692850213224765\n"
     ]
    }
   ],
   "source": [
    "voting_X = blend_X_test\n",
    "\n",
    "voting_mean = np.mean(voting_X, axis=1)\n",
    "score_mean = r2_score(y_full, voting_mean)\n",
    "print('равные веса', score_mean)\n",
    "\n",
    "voting_median = np.median(voting_X, axis=1)\n",
    "score_median = r2_score(y_full, voting_median)\n",
    "print('робастное усреднение', score_median)\n",
    "\n",
    "from scipy import stats\n",
    "voting_trimmed = stats.trim_mean(voting_X, proportiontocut=0.1, axis=1)\n",
    "score_trimmed = r2_score(y_full, voting_trimmed)\n",
    "print('отбрасываем крайние 20%', score_trimmed)\n",
    "\n",
    "print('оптимальные веса', score_blending)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение результатов A/B тестов\n",
    "\n",
    "На основе A/B тестов:\n",
    "- Pseudo-labeling показал улучшение\n",
    "- Ridge Blending дал лучший результат\n",
    "- Feature Jittering & Label Smoothing не улучшают\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUhfcrcKO0D1"
   },
   "source": [
    "В этом ноутбуке мы решили не использовать перебор параметров по optuna, так как чтобы сделать это на выбарнной стратегии валидации нужно очень много времени. При этом ослабление стратегии валидации дает глобальное ухудшение по качетсву на закрытых тестах. Поэтому мы рассмотрели несколько наборов параметров для каждой модели. Параметры мы старались подбирать максимально различными между собой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_oofs = {}\n",
    "models_preds = {}\n",
    "models_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f37601a05d440bb2eb0db48a7c78ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb1_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98d3d0ad5dc4f9e8b30369bf0d26e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb2_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c4a3cedd6a42d88556498c2bf4c9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb3_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35045c93d38414eb250cbe990cdb9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb4_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55df62d356bf466fac2bac1ff3144969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb5_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14d3df22947428089139ed089d65171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb6_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57ce1f8a368400a928a69c794d2ec3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb7_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a937b3c0a74e9cbd43e44dac05b6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb8_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c6a9b8d0ff4aecb6d23018b6c922b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb9_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67154f7a46484f9795331cd86491983b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb10_base  :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_configs = [\n",
    "    {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8},\n",
    "    {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.03, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1},\n",
    "    {'n_estimators': 250, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 0.7, 'min_child_weight': 3},\n",
    "    {'n_estimators': 350, 'max_depth': 7, 'learning_rate': 0.02, 'subsample': 0.75, 'colsample_bytree': 0.85, 'reg_lambda': 0.1},\n",
    "    {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.85, 'colsample_bytree': 0.9},\n",
    "    {'n_estimators': 180, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.75, 'min_child_weight': 5},\n",
    "    {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.04, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.1},\n",
    "    {'n_estimators': 250, 'max_depth': 4, 'learning_rate': 0.06, 'subsample': 0.9, 'colsample_bytree': 0.85, 'reg_alpha': 0.05, 'reg_lambda': 0.05},\n",
    "    {'n_estimators': 350, 'max_depth': 7, 'learning_rate': 0.025, 'subsample': 0.75, 'colsample_bytree': 0.9, 'min_child_weight': 2},\n",
    "    {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8, 'colsample_bytree': 0.7, 'gamma': 0.05},\n",
    "]\n",
    "\n",
    "for i, params in enumerate(xgb_configs, 1):\n",
    "    model = XGBRegressor(**params, random_state=42, n_jobs=-1, device='cuda', tree_method='hist', verbosity=0)\n",
    "    oofs, preds, score = train_with_pseudolabeling(type(model), model.get_params(), X_full_feat, y_full, X_test_feat, f'xgb{i}', use_aug=False)\n",
    "    models_oofs[f'xgb{i}'] = oofs\n",
    "    models_preds[f'xgb{i}'] = preds\n",
    "    models_scores[f'xgb{i}'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeefbe078ab24b0f97a730b7d9d719c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lgbm1_base  :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4654e0a2b1de4e69a110caad2f8e940c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lgbm2_base  :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e342988af3c49b7957cf7c5732b8c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lgbm3_base  :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad72b23888dd414ab290b3091b60182b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lgbm4_base  :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11a061f37cd49b989b426850ed09b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lgbm5_base  :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f304c754c4a4c40be0656b06e9d34c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lgbm6_base  :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdb131980474a9e81fcfa38936cbda2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lgbm7_base  :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65272e2054cd4e7b80e511fd060dad87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lgbm8_base  :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94569a88381d42999041a56184d04db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lgbm9_base  :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad875128c6748e8b6c4d58a4ca96e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lgbm10_base :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgbm_configs = [\n",
    "    {'n_estimators': 200, 'num_leaves': 31, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8},\n",
    "    {'n_estimators': 300, 'num_leaves': 63, 'learning_rate': 0.03, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1},\n",
    "    {'n_estimators': 250, 'num_leaves': 47, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 0.7, 'min_child_samples': 20},\n",
    "    {'n_estimators': 350, 'num_leaves': 55, 'learning_rate': 0.02, 'subsample': 0.75, 'colsample_bytree': 0.85, 'reg_lambda': 0.1},\n",
    "    {'n_estimators': 180, 'num_leaves': 25, 'learning_rate': 0.06, 'subsample': 0.85, 'colsample_bytree': 0.9, 'min_child_samples': 25},\n",
    "    {'n_estimators': 300, 'num_leaves': 70, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.75, 'reg_alpha': 0.05},\n",
    "    {'n_estimators': 250, 'num_leaves': 40, 'learning_rate': 0.04, 'subsample': 0.9, 'colsample_bytree': 0.8, 'min_child_samples': 15},\n",
    "    {'n_estimators': 400, 'num_leaves': 50, 'learning_rate': 0.025, 'subsample': 0.75, 'colsample_bytree': 0.85, 'reg_lambda': 0.05},\n",
    "    {'n_estimators': 320, 'num_leaves': 60, 'learning_rate': 0.035, 'subsample': 0.82, 'colsample_bytree': 0.88, 'min_child_samples': 18},\n",
    "    {'n_estimators': 280, 'num_leaves': 35, 'learning_rate': 0.045, 'subsample': 0.88, 'colsample_bytree': 0.72, 'reg_alpha': 0.08, 'reg_lambda': 0.08},\n",
    "]\n",
    "\n",
    "for i, params in enumerate(lgbm_configs, 1):\n",
    "    model = LGBMRegressor(**params, device='gpu', random_state=42, n_jobs=-1, verbose=-1)\n",
    "    oofs, preds, score = train_with_pseudolabeling(type(model), model.get_params(), X_full_feat, y_full, X_test_feat, f'lgbm{i}', use_aug=False)\n",
    "    models_oofs[f'lgbm{i}'] = oofs\n",
    "    models_preds[f'lgbm{i}'] = preds\n",
    "    models_scores[f'lgbm{i}'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861f4ab536544da7b5f73f9ade78ffac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cat1_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86af6f7cf0a4532b4d8f159a24b9549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cat2_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011003ca7ef74796b7fd0c1db632ba97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cat3_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b7c75d7f2d4eabb5918858b3fed780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cat4_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264b816f2e74433492160f15f69a6d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cat5_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc208785b0f40f1bd66c6940b7b3d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cat6_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0640e80c66a4516aa1793bdbc94fc1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cat7_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3747dbe6cc394b2294d890aba399ddbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cat8_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af9180dc01b4853baa8351dfe89a7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cat9_base   :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69776f96b3e842b5be3f04b0befdcbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cat10_base  :   0%|          | 0/15 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_configs = [\n",
    "    {'iterations': 200, 'depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'bootstrap_type': 'Bernoulli'},\n",
    "    {'iterations': 300, 'depth': 6, 'learning_rate': 0.03, 'subsample': 0.7, 'l2_leaf_reg': 3, 'bootstrap_type': 'Bernoulli'},\n",
    "    {'iterations': 250, 'depth': 7, 'learning_rate': 0.05, 'subsample': 0.9, 'l2_leaf_reg': 5, 'bootstrap_type': 'Bernoulli'},\n",
    "    {'iterations': 350, 'depth': 6, 'learning_rate': 0.02, 'subsample': 0.75, 'l2_leaf_reg': 2, 'bootstrap_type': 'Bernoulli'},\n",
    "    {'iterations': 180, 'depth': 8, 'learning_rate': 0.06, 'subsample': 0.85, 'l2_leaf_reg': 4, 'bootstrap_type': 'Bernoulli'},\n",
    "    {'iterations': 300, 'depth': 5, 'learning_rate': 0.04, 'subsample': 0.8, 'l2_leaf_reg': 1, 'bootstrap_type': 'Bernoulli'},\n",
    "    {'iterations': 250, 'depth': 7, 'learning_rate': 0.035, 'subsample': 0.9, 'l2_leaf_reg': 6, 'bootstrap_type': 'Bernoulli'},\n",
    "    {'iterations': 320, 'depth': 6, 'learning_rate': 0.045, 'subsample': 0.82, 'l2_leaf_reg': 3.5, 'bootstrap_type': 'Bernoulli'},\n",
    "    {'iterations': 280, 'depth': 8, 'learning_rate': 0.028, 'subsample': 0.88, 'l2_leaf_reg': 4.5, 'bootstrap_type': 'Bernoulli'},\n",
    "    {'iterations': 360, 'depth': 5, 'learning_rate': 0.038, 'subsample': 0.78, 'l2_leaf_reg': 2.5, 'bootstrap_type': 'Bernoulli'},\n",
    "]\n",
    "\n",
    "for i, params in enumerate(cat_configs, 1):\n",
    "    model = CatBoostRegressor(**params, random_seed=42, verbose=0, task_type='GPU')\n",
    "    oofs, preds, score = train_with_pseudolabeling(type(model), model.get_params(), X_full_feat, y_full, X_test_feat, f'cat{i}', use_aug=False)\n",
    "    models_oofs[f'cat{i}'] = oofs\n",
    "    models_preds[f'cat{i}'] = preds\n",
    "    models_scores[f'cat{i}'] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWAQVmyTP2o8"
   },
   "source": [
    "## Ансамбли"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W67DutGdPbtR"
   },
   "source": [
    "Добавим модель бейзлайна в общий список для сравнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T02:09:57.513101Z",
     "iopub.status.busy": "2025-12-15T02:09:57.512961Z",
     "iopub.status.idle": "2025-12-15T02:09:57.515572Z",
     "shell.execute_reply": "2025-12-15T02:09:57.515206Z"
    },
    "id": "vQ5QXi1fM_o-",
    "outputId": "40791048-c0ba-4fbb-f805-8d4f1647a67d"
   },
   "outputs": [],
   "source": [
    "if BASELINE_AVAILABLE:\n",
    "    models_oofs['baseline'] = [baseline_train_oof for _ in range(n_repeats)]\n",
    "    models_preds['baseline'] = [baseline_test for _ in range(n_repeats)]\n",
    "    models_scores['baseline'] = baseline_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAJ_V86zP1Yd"
   },
   "source": [
    "Далее реализованы функции для выбора моделей в итоговый ансамбль, пождобную стратегию использовали лидеры соревнования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "65TZaDhzPzRw"
   },
   "outputs": [],
   "source": [
    "def compute_permutation_importance(models_list, n_permutations=3):\n",
    "    oofs_averaged = {}\n",
    "    for model_name in models_list:\n",
    "        oofs_averaged[model_name] = np.mean(models_oofs[model_name], axis=0)\n",
    "\n",
    "    blend_X = np.column_stack([oofs_averaged[m] for m in models_list])\n",
    "\n",
    "    ridge = Ridge(alpha=0.01, fit_intercept=False, random_state=42)\n",
    "    ridge.fit(blend_X, y_full)\n",
    "    baseline_score = r2_score(y_full, ridge.predict(blend_X))\n",
    "\n",
    "    perm_scores = {}\n",
    "    for model_name in tqdm(models_list, desc='Computing importance'):\n",
    "        scores = []\n",
    "        for _ in range(n_permutations):\n",
    "            blend_X_perm = blend_X.copy()\n",
    "            model_idx = models_list.index(model_name)\n",
    "            blend_X_perm[:, model_idx] = np.random.permutation(blend_X_perm[:, model_idx])\n",
    "\n",
    "            ridge_temp = Ridge(alpha=0.01, fit_intercept=False, random_state=42)\n",
    "            ridge_temp.fit(blend_X_perm, y_full)\n",
    "            perm_score = r2_score(y_full, ridge_temp.predict(blend_X_perm))\n",
    "\n",
    "            scores.append(baseline_score - perm_score)\n",
    "\n",
    "        perm_scores[model_name] = np.mean(scores)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'Model': perm_scores.keys(),\n",
    "        'Importance': perm_scores.values()\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "\n",
    "def find_correlated_models(models_list, threshold=0.9999):\n",
    "    oofs_averaged = {}\n",
    "    for model_name in models_list:\n",
    "        oofs_averaged[model_name] = np.mean(models_oofs[model_name], axis=0)\n",
    "\n",
    "    oofs_df = pd.DataFrame(oofs_averaged)\n",
    "    correlations = oofs_df.corr()\n",
    "\n",
    "    corr_pairs = []\n",
    "    for i, col1 in enumerate(correlations.columns):\n",
    "        for j, col2 in enumerate(correlations.columns):\n",
    "            if i < j and correlations.iloc[i, j] > threshold:\n",
    "                corr_pairs.append((col1, col2, correlations.iloc[i, j]))\n",
    "\n",
    "    return sorted(corr_pairs, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "def create_model_groups(groups_dict):\n",
    "    for group_name, group_models in groups_dict.items():\n",
    "        oofs_grouped = []\n",
    "        preds_grouped = []\n",
    "\n",
    "        for repeat in range(n_repeats):\n",
    "            oof_r = np.mean([models_oofs[m][repeat] for m in group_models], axis=0)\n",
    "            pred_r = np.mean([models_preds[m][repeat] for m in group_models], axis=0)\n",
    "            oofs_grouped.append(oof_r)\n",
    "            preds_grouped.append(pred_r)\n",
    "\n",
    "        models_oofs[group_name] = oofs_grouped\n",
    "        models_preds[group_name] = preds_grouped\n",
    "        models_scores[group_name] = r2_score(y_full, np.mean(oofs_grouped, axis=0))\n",
    "\n",
    "        print(f'Created group {group_name}: {len(group_models)} models, R² = {models_scores[group_name]:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOMoDTIrTWNR"
   },
   "source": [
    "### Запуск ансамблей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ER0TtNEWgum"
   },
   "source": [
    "Ищем скоррелированные пары моделей, а также ранжируем их по важности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Og0YPXPbUAXA",
    "outputId": "fb950c42-da5d-434d-95a3-0c85b638d0b0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795319ce76c44bccb8b8db3261a7b9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing importance:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_base_models = [m for m in models_oofs.keys() if m != 'baseline']\n",
    "perm_df_1 = compute_permutation_importance(all_base_models, n_permutations=3)\n",
    "corr_pairs = find_correlated_models(all_base_models, threshold=0.9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGyo53sLSgfL"
   },
   "source": [
    "На основе типа моделей и correlation analysis создаем группы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtaBkMwqWqx6",
    "outputId": "5f42f36b-b3d7-4e43-98e2-8df29bc786c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created group xgb_top_group: 3 models, R² = 0.869309\n",
      "Created group lgbm_top_group: 3 models, R² = 0.869198\n",
      "Created group cat_top_group: 3 models, R² = 0.868272\n",
      "Всего выбрано моделей 13\n"
     ]
    }
   ],
   "source": [
    "groups_to_create = {}\n",
    "\n",
    "top_xgb = [m for m in perm_df_1.head(15)['Model'] if 'xgb' in m]\n",
    "if len(top_xgb) >= 3:\n",
    "    groups_to_create['xgb_top_group'] = top_xgb[:3]\n",
    "\n",
    "top_lgbm = [m for m in perm_df_1.head(15)['Model'] if 'lgbm' in m]\n",
    "if len(top_lgbm) >= 3:\n",
    "    groups_to_create['lgbm_top_group'] = top_lgbm[:3]\n",
    "\n",
    "top_cat = [m for m in perm_df_1.head(15)['Model'] if 'cat' in m]\n",
    "if len(top_cat) >= 3:\n",
    "    groups_to_create['cat_top_group'] = top_cat[:3]\n",
    "\n",
    "if groups_to_create:\n",
    "    create_model_groups(groups_to_create)\n",
    "\n",
    "top_models = perm_df_1.head(10)['Model'].tolist()\n",
    "\n",
    "selected_models = top_models + list(groups_to_create.keys())\n",
    "print('Всего выбрано моделей', len(selected_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIUEks2taV5o"
   },
   "source": [
    "Теперь выберем итоговый список из 7 лучших моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUhwJyUOZyyd",
    "outputId": "484b8628-ab66-451e-b2e9-610840991b1d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08885f189daa43aa8fd11066b361bb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing importance:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model    Importance\n",
      "          xgb6  3.757238e-05\n",
      "          xgb9  9.484145e-06\n",
      " xgb_top_group  4.906292e-06\n",
      "         lgbm4  4.844093e-06\n",
      "         lgbm2  2.553880e-06\n",
      "          cat2  2.368512e-06\n",
      "          cat9  2.149385e-06\n",
      "          cat5  1.862510e-06\n",
      "lgbm_top_group  1.363201e-06\n",
      "          cat4  1.051475e-06\n",
      "          cat7  9.563283e-07\n",
      "          cat3  4.913791e-07\n",
      " cat_top_group  1.418980e-08\n",
      "      baseline -9.118151e-09\n"
     ]
    }
   ],
   "source": [
    "if 'baseline' in models_oofs:\n",
    "    selected_models.append('baseline')\n",
    "\n",
    "perm_df_final = compute_permutation_importance(selected_models, n_permutations=3)\n",
    "print(perm_df_final.to_string(index=False))\n",
    "\n",
    "final_models = perm_df_final.head(7)['Model'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w32mdaktazyn"
   },
   "source": [
    "### Blending & Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGVqUHDQakIP"
   },
   "source": [
    "Теперь будем строить Blending на выбранных моделях. Практика и опыт участников соревнования показали, что именно этот вид ансамбля показывает наилучший результат. Также мы применяем регуляризацию с помощью ридж-регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdTCB1Z1b4-W",
    "outputId": "6eaa3d90-b078-43f1-9029-9d02f3534634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL RIDGE OOF R² = 0.869461\n",
      "Веса моделей:\n",
      "        Model  Coefficient\n",
      "         xgb6     0.827501\n",
      "         xgb9     0.596657\n",
      "        lgbm2     0.540200\n",
      "         cat9     0.188468\n",
      "         cat2    -0.188652\n",
      "        lgbm4    -0.403095\n",
      "xgb_top_group    -0.561057\n"
     ]
    }
   ],
   "source": [
    "models_oofs_averaged = {}\n",
    "models_preds_averaged = {}\n",
    "\n",
    "for model_name in final_models:\n",
    "    oof_avg = np.mean([models_oofs[model_name][r] for r in range(n_repeats)], axis=0)\n",
    "    pred_avg = np.mean([models_preds[model_name][r] for r in range(n_repeats)], axis=0)\n",
    "    models_oofs_averaged[model_name] = oof_avg\n",
    "    models_preds_averaged[model_name] = pred_avg\n",
    "\n",
    "blend_X = np.column_stack([models_oofs_averaged[m] for m in final_models])\n",
    "blend_test = np.column_stack([models_preds_averaged[m] for m in final_models])\n",
    "\n",
    "ridge_final = Ridge(alpha=0.001, fit_intercept=False, random_state=42)\n",
    "ridge_final.fit(blend_X, y_full)\n",
    "\n",
    "ridge_oof = ridge_final.predict(blend_X)\n",
    "ridge_test = ridge_final.predict(blend_test)\n",
    "ridge_r2 = r2_score(y_full, ridge_oof)\n",
    "\n",
    "print(f'FINAL RIDGE OOF R² = {ridge_r2:.6f}')\n",
    "\n",
    "print('Веса моделей:')\n",
    "coefs_df = pd.DataFrame({\n",
    "    'Model': final_models,\n",
    "    'Coefficient': ridge_final.coef_\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "print(coefs_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnvRUAEye3XS"
   },
   "source": [
    "## Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psWceZPve7WT"
   },
   "source": [
    "Теперь построим сравнительную таблицу по всем моделям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvZ_tm86fhwV",
    "outputId": "a9f59179-4d45-402e-edb9-34f7db31edb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         Model  R² (OOF)\n",
      "   Ridge_Blend  0.869461\n",
      "          xgb6  0.869419\n",
      "          xgb9  0.869367\n",
      "          xgb4  0.869319\n",
      " xgb_top_group  0.869309\n",
      "         lgbm2  0.869231\n",
      "         lgbm9  0.869208\n",
      "lgbm_top_group  0.869198\n",
      "          xgb3  0.869166\n",
      "         lgbm6  0.869139\n",
      "         lgbm8  0.869130\n",
      "         lgbm4  0.869107\n",
      "         lgbm3  0.868937\n",
      "        lgbm10  0.868922\n",
      "         lgbm7  0.868910\n",
      "         lgbm5  0.868877\n",
      "          xgb2  0.868823\n",
      "         lgbm1  0.868791\n",
      "          cat5  0.868661\n",
      "          cat3  0.868583\n",
      "          xgb8  0.868539\n",
      "          cat8  0.868473\n",
      " cat_top_group  0.868272\n",
      "          cat9  0.868223\n",
      "          xgb1  0.868162\n",
      "          cat7  0.868075\n",
      "         cat10  0.868065\n",
      "          cat6  0.867871\n",
      "          cat2  0.867750\n",
      "          xgb5  0.867715\n",
      "          cat1  0.867538\n",
      "         xgb10  0.867342\n",
      "          cat4  0.867212\n",
      "          xgb7  0.867012\n",
      "      baseline  0.858277\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Model': list(models_scores.keys()) + ['Ridge_Blend'],\n",
    "    'R² (OOF)': list(models_scores.values()) + [ridge_r2]\n",
    "}).sort_values('R² (OOF)', ascending=False)\n",
    "\n",
    "print('\\n' + results_df.to_string(index=False))\n",
    "\n",
    "best_model = results_df.iloc[0]['Model']\n",
    "best_r2 = results_df.iloc[0]['R² (OOF)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50dRTObwg0kV"
   },
   "source": [
    "А также сравним лучшую модель с бейзлайном и посмотрим, насколько увеличилась метрика."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FUA3Tv3OfeZA",
    "outputId": "1cef6ebb-7e3a-4e42-ddb5-9d2b424ff197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Лучшая модель: Ridge_Blend\n",
      "Лучшее R²: 0.869461\n",
      "\n",
      "Улучшение относительно бейзлайна:\n",
      "  Baseline:  R² = 0.858277\n",
      "  Advanced:  R² = 0.869461\n",
      "  Delta R²:  +0.011184\n",
      "  Delta %:   +1.30%\n"
     ]
    }
   ],
   "source": [
    "print(f'Лучшая модель: {best_model}')\n",
    "print(f'Лучшее R²: {best_r2:.6f}')\n",
    "\n",
    "if BASELINE_AVAILABLE:\n",
    "    improvement = best_r2 - baseline_r2\n",
    "    improvement_pct = (improvement / baseline_r2) * 100\n",
    "    print(f'\\nУлучшение относительно бейзлайна:')\n",
    "    print(f'  Baseline:  R² = {baseline_r2:.6f}')\n",
    "    print(f'  Advanced:  R² = {best_r2:.6f}')\n",
    "    print(f'  Delta R²:  {improvement:+.6f}')\n",
    "    print(f'  Delta %:   {improvement_pct:+.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmAO1m5NTeCW"
   },
   "source": [
    "Видим хороший прирост по метрике в ходе исследования моделей. Минимальное требование выполнено. Построим файл submission по предсказаниям лучшей модели для получения скоров на kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-15T02:10:46.850811Z",
     "iopub.status.busy": "2025-12-15T02:10:46.850717Z",
     "iopub.status.idle": "2025-12-15T02:10:47.594764Z",
     "shell.execute_reply": "2025-12-15T02:10:47.594358Z"
    },
    "id": "oeIrhxppM_pB",
    "outputId": "0901d624-031d-4a5e-c432-7954374ab57c"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'FloodProbability': ridge_test\n",
    "})\n",
    "\n",
    "submission.to_csv('results/solution.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
